# 1.RAG

大模型的知识更新问题将成为模型的一个重要痛点

RAG在推理过程中分为两个阶段：检索和内容生成。

完成检索之后，可以获取到一些与用户输入相关的可靠外部知识。在内容生成阶段，通过一个结构化的prompt模板约束，将这些外部知识添加到用户的问题中，并传递给语言模型。模型基于知识增强的prompt，通过自己的大量参数计算，就可以生成一个针对该用户问题的更准确的答案。

微调与RAG

模型微调是指在一个特定任务上用一定量的数据来训练模型的过程，通过在特定数据集上微调可以提高模型在特定数据集上的性能



RAG的意义

知识更新问题，大模型生成结果的不可解释性问题，大模型训练成本问题



RAG的工作流程涉及3个主要阶段：

数据准备：向量数据库，搜索引擎

数据召回：从大型文本数据库中检索与输入相关的信息。为了尽可能保证正确答案被送入生成器部分，数据召回部分的召回率显得非常重要。一般来说，召回的数量越大，正确答案被召回的概率也就越高，但同时会面临大模型上下文长度限制的问题。

答案生成：RAG系统就将其与用户的问题和相关数据一起传递给生成器（LLM）。LLM利用检索到的数据和用户的查询或任务生成输出



# 2 语言模型基础

Transformer由编码器（encoder）和解码器（decoder）两大部分构成。

Transformer中输入单词的词嵌入包含单词编码和位置编码。



词嵌入方法，如NNLM、Word2vector、
 GloVe等，这几种方法本质上都是先训练好一个语言模型，然后输入单词取模型的隐藏层表示来作为单词的词向量表示。这些方法都是静态的表示方法，即一旦模型确定则单词的词向量表示也确定。虽然这些语言模型的词表征方法在下游任务中都取得了优异的表现。但大多情况下单
 词的语义是随语境变化的，因此这些方法得到的词向量有一定缺陷，尤其无法表达多义词。

与静态词嵌入方法不同，ELMo（来自语言模型的嵌入）采用动态方法生成词嵌入，它基于训练好的语言模型，并能根据上下文实时调整词嵌入，有效地缓解了词义歧义的问题。



GPT（Generative Pre-Trained，生成式预训练）

自然语言理解（NLU）



在机器学习领域，有判别式模型（Discriminative Model）和生成式模型（Generative Model）两种

生成式模型更适合大规模数据学习，判别式模型更适合小样本标注数据

GPT中使用了生成式（无监督）的预训练和判别式（有监督）的微调。

LLaMA（Large Language Model Meta AI, Meta AI大型语言模型）

benchmark一般是和同行中比较牛的算法比较，比牛算法还好，那你可以考虑发好一点的会议/期刊；baseline一般是自己[算法优化](https://marketing.csdn.net/p/3127db09a98e0723b83b2914d9256174?pId=2782&utm_source=glcblog&spm=1001.2101.3001.7020)和调参过程中自己和自己比较，目标是越来越好，当性能超过benchmark时，可以发表了，当性能甚至超过SOTA时，恭喜你，考虑投顶会顶刊啦。

本章介绍了语言模型的基础原理，包含Transformer、自动编码器、自回归模型等的原理。在Transformer的原理介绍中，以语言翻译为例介绍了Transformer的工作流程，以及词嵌入、编码器、解码器等核心部分。而在词嵌入中，我们详细介绍了单词编码（神经网络编码和词向量编码）
 和位置编码，并通过公式讲解和代码帮助理解底层构造原理。在编码器和解码器中，我们重点讲解了注意力机制和前馈层。在自动编码器的原理一节中，我们介绍了ELMo和BERT，介绍了它们的原理和内部机制。最后，在自回归模型中，我们介绍了GPT和LLaMA，这两种也是当下最
 热门的语言模型，我们介绍了它们的数学原理和对原始transformer架构的改进。



# 3.文本召回模型

在召回环节中，需要使用向量化模型（文本向量检索模型）进行两个环节的处理：文本片段向量化和用户查询向量化。。文本向量检索模型可大致分为两类：一类是基于BERT、GPT等深度学习模型的稠密向量检索模型；另一类是以TF-IDF、BM25为代表的稀疏向量检索模型。稠密向量检索模型更擅长提取文本中的语义信息，稀疏向量检索模型则更擅长提取关键词信息。

文本向量空间：对齐性和均匀性

对称检索和非对称检索：对称检索要求查询内容和答案内容具有相近的意思，非对称检索是指根据问题召回相关答案（要求模型能够将问题和答案映射到同一空间）

# 4 核心技术与优化方法

4.1 提示词工程

如何写提示词

在RAG场景下，应避免将更有可能包含正确答案的召回文本片段放在LLM输入的中间部分，两头放概率高的，1，3，5，n，6，4，2

4.2 文本切块

句子向量由单词向量平均求得，所以切块过长会丢失信息，并且token消耗过大

切块过短，丢失主题，不易总结

切块策略并没有所谓的“最佳”实践，需要根据自己的应用场景进行分析和实验来进行选择。

固定大小文本切块langchain.text_splitter.RecursiveCharacterTextSpliter

NLTK文本切块

特殊格式文本切块

基于深度学习模型的文本切块SeqModel

4.3 向量数据库

Faiss，本质上并不能被看作一种现代数据库，因为它不支持数据管理和分布式等功能。它只是实现了高效检索的核心算法（提供了高效检索方法）而已。

Milvus，会在Faiss的基础上进行进一步开发，以优化灵活性、易用性和可靠性。

4.4 召回优化

在向量召回的过程中会存在一些问题，比如文本切块会损失全局信息、用户查询内容描述不准确等，这些问题会影响召回文本的质量。

短文本全局信息增强

召回内容上下文扩充（父文本内容召回）

文本多向量表示：用问题召回问题

查询内容优化

召回文本重排序

多检索器融合

结合元数据召回

4.5 效果评估

召回的文本中是否包含用户问题对应的答案严重，影响着LLM的最终回答效果。

文本切块策略、向量化模型、召回策略等因素都会影响最终的召回效果。

召回环节评估

模型回答评估

4.6 LLM能力优化